{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-98T1e0Fo-_"
      },
      "source": [
        "# Introduction to Convolutional Neural Networks \n",
        "\n",
        "\n",
        "** Ecole Centrale Nantes **\n",
        "\n",
        "** Diana Mateus **\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWvMyUuIFo_F"
      },
      "source": [
        "Sakthi Vikneswar Suresh Babu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbzD2vUXFo_J"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sO2dQfUFo_L"
      },
      "source": [
        "### Loading the dataset\n",
        "Start by runing the following lines to load and visualize the data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UNCOMMENT IF USING COLAB\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "IMDIR = '/content/drive/MyDrive/Colab Notebooks/dataset'"
      ],
      "metadata": {
        "id": "tnoNobk1KaPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "__Yz2Cih-Epu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMhp19cHFo_M"
      },
      "outputs": [],
      "source": [
        "def load_dataset(IMDIR):\n",
        "    train_dataset = h5py.File(IMDIR+'/train_catvnoncat.h5', \"r\")\n",
        "    train_x = np.array(train_dataset[\"train_set_x\"][:]) \n",
        "    train_y = np.array(train_dataset[\"train_set_y\"][:])\n",
        "    test_dataset = h5py.File(IMDIR+'/test_catvnoncat.h5', \"r\")\n",
        "    test_x = np.array(test_dataset[\"test_set_x\"][:]) \n",
        "    test_y = np.array(test_dataset[\"test_set_y\"][:])\n",
        "    classes = np.array(test_dataset[\"list_classes\"][:]) \n",
        "    \n",
        "    train_y = train_y.reshape((1, train_y.shape[0]))\n",
        "    test_y = test_y.reshape((1, test_y.shape[0]))\n",
        "    \n",
        "    return train_x, train_y, test_x, test_y, classes\n",
        "\n",
        "train_x, train_y, test_x, test_y, classes=load_dataset(IMDIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRKTEbV8Fo_O"
      },
      "source": [
        "#### Visualize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XY74AXWEFo_O"
      },
      "outputs": [],
      "source": [
        "# run several times to visualize different data points\n",
        "# the title shows the ground truth class labels (0=no cat , 1 = cat)\n",
        "index = np.random.randint(low=0,high=train_y.shape[1])\n",
        "plt.imshow(train_x[index])\n",
        "plt.title(\"Image \"+str(index)+\" label \"+str(train_y[0,index]))\n",
        "plt.show()\n",
        "print (\"Train X shape: \" + str(train_x.shape))\n",
        "print (\"We have \"+str(train_x.shape[0]), \n",
        "       \"images of dimensionality \" \n",
        "       + str(train_x.shape[1])+ \"x\"\n",
        "       + str(train_x.shape[2])+ \"x\"\n",
        "       + str(train_x.shape[3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucx9VpPDFo_R"
      },
      "source": [
        "#### Preprocessing\n",
        "In the following lines we vectorize the images (Instead of a 2-D image we will give as input to the models a 1-D vector). The normalization makes the image intensities be between 0 and 1, and converts the images to floats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tx15h1XFo_R"
      },
      "outputs": [],
      "source": [
        "train_x, train_y, test_x, test_y, classes=load_dataset(IMDIR)\n",
        "train_x = train_x.reshape(train_x.shape[0], -1).T\n",
        "test_x = test_x.reshape(test_x.shape[0], -1).T\n",
        "print (\"Train X shape: \" + str(train_x.shape))\n",
        "print (\"Train Y shape: \" + str(train_y.shape))\n",
        "print (\"Test X shape: \" + str(test_x.shape))\n",
        "print (\"Test Y shape: \" + str(test_y.shape))\n",
        "\n",
        "train_x = train_x/255.\n",
        "test_x = test_x/255."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SWukehhFo_g"
      },
      "source": [
        "### 2. CNNs with Keras\n",
        "\n",
        "Adapt the example in this website https://keras.io/examples/vision/mnist_convnet/ to our problem. To this end:\n",
        "- change the number of classes and the input size\n",
        "- remove the expand_dims(x_train, -1): it is not necessary to expand the dimensions since our input is 3-dimensional \n",
        "- you may need to transpose the labels vector\n",
        "- change the categorical cross-entropy to the binary cross entropy given that our problem is binary classification. \n",
        "- also change the softmax to sigmoid, the more appropriate activation function for binary data\n",
        "\n",
        "We can choose a single neuron output passed through sigmoid, and then set a threshold to choose the class, or use two neuron output and then perform a softmax.\n",
        "\n",
        "**2.1** Can you get the accuracy better than in our hand single-neuron model?Try different configurations and explain the changes you have made.\n",
        "\n",
        "**2.2** Compute the train and test loss and accuracy after the model has been trained.  What model parameters does the ``fit`` function retain?\n",
        "\n",
        "**2.3** How many parameters does the network have, explain where the number comes from.\n",
        "\n",
        "**2.4** What is the receptive field of the network https://distill.pub/2019/computing-receptive-fields/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhzjC8_VFo_h"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yv4lWad0Fo_j"
      },
      "outputs": [],
      "source": [
        "#Model/Data parameters\n",
        "num_classes = 2\n",
        "input_shape = train_x.shape[1:4]\n",
        "# the data, split between train and test sets\n",
        "x_train, y_train, x_test, y_test,classes=load_dataset(IMDIR)\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "#x_train = np.expand_dims(x_train, -1)\n",
        "#x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhgPycoVFo_l"
      },
      "outputs": [],
      "source": [
        "#build the model\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LL0w6OeFFo_o"
      },
      "outputs": [],
      "source": [
        "#compile and fit\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LX_FTgzFo_p"
      },
      "outputs": [],
      "source": [
        "#evaluate\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# receptive field\n",
        "\n",
        "layers = 4 # 2 conv2d & 2 maxpool\n",
        "stride = np.ones(layers)\n",
        "kernel_size = [2, 2, 2, 2] # 2 for conv2d and maxpool\n",
        "recept_field = 0\n",
        "\n",
        "for i in range(layers):\n",
        "    stride_prod = 1\n",
        "    for j in range(layers-1):\n",
        "        stride_prod *= stride[j]\n",
        "    recept_field += (kernel_size[i] - 1) * stride_prod\n",
        "recept_field += 1\n",
        "print (\"Receptive field for this network is : \", int(recept_field))"
      ],
      "metadata": {
        "id": "uGboJ9JuXF4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX_LrVY_Fo_q"
      },
      "source": [
        "## BONUS: \n",
        "Replace the fit function by your own tensorflow  implementation\n",
        "\n",
        "1. Instantiate one of keras.optimizers to train the model.\n",
        "\n",
        "optimizer = \n",
        "\n",
        "2. Instantiate a loss from keras.losses\n",
        "\n",
        "loss_fn = \n",
        "\n",
        "3. Prepare the metrics. Instatiate the metrics from keras.metrics\n",
        "\n",
        "train_acc_metric =\n",
        "val_acc_metric =\n",
        "\n",
        "4. Stochastic Gradient Loop\n",
        "    * Iterate over the dataset in batches with \n",
        "    * Open a GradientTape() scope \n",
        "    * Inside this scope call the model (forward pass)\n",
        "    * Compute the loss outside the scope\n",
        "    * Retrieve the weight gradients\n",
        "    * Use the optimimzer to update the weights with the gradients\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-PQ71UOFo_r"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tf2",
      "language": "python",
      "name": "tf2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}